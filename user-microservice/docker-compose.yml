version: '3.8'
services:
    postgres:
        image: postgres:alpine
        container_name: postgres
        hostname: postgres
        ports: 
            - 6432:5432
        environment: 
            POSTRGRES_USER: postgres
            POSTGRES_PASSWORD: root
            POSTGRES_DB: neutrino_users

    elastic:
        image: docker.elastic.co/elasticsearch/elasticsearch:7.13.0
        container_name: elastic
        hostname: elastic
        ulimits:
            memlock:
              soft: -1
              hard: -1
        environment:
            - node.name=elastic
            - discovery.type=single-node
            - cluster.name=es-docker-cluster
            # - cluster.initial_master_nodes=elastic
            - bootstrap.memory_lock=true
            - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
        volumes:
            - data01:/usr/share/elasticsearch/data
        ports:
            - 9200:9200

    zookeeper:
        image: confluentinc/cp-zookeeper:latest
        hostname: zookeeper
        container_name: zookeeper
        environment:
            ZOOKEEPER_CLIENT_PORT: 2181
            ZOOKEEPER_TICK_TIME: 2000
    
    kafka:
        image: confluentinc/cp-kafka:latest
        hostname: kafka
        container_name: kafka
        depends_on:
            - zookeeper
        links:
            - zookeeper
        ports:
            - 9092:9092
            - 29092:29092
            - 9101:9101
        environment:
            KAFKA_BROKER_ID: 1
            KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
            KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
            KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
            KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
            KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
            KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
            KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
            KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
            KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
            KAFKA_JMX_PORT: 9101
            KAFKA_JMX_HOSTNAME: localhost

    schema-registry:
        image: confluentinc/cp-schema-registry:latest
        hostname: schema-registry
        container_name: schema-registry
        environment:
            SCHEMA_REGISTRY_HOST_NAME: schema-registry
            SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: kafka:29092
            SCHEMA_REGISTRY_LISTENERS: http://0.0.0.0:8081
        depends_on:
            - kafka
        ports:
            - 8081:8081

    kafka-connect:
        image: confluentinc/cp-kafka-connect-base:latest
        hostname: kafka-connect
        container_name: kafka-connect
        depends_on:
            - kafka
            - schema-registry
        ports:
            - 8083:8083
        environment:
            CONNECT_BOOTSTRAP_SERVERS: kafka:29092
            CONNECT_REST_PORT: 8083
            CONNECT_GROUP_ID: kafka-connect
            CONNECT_CONFIG_STORAGE_TOPIC: _connect-configs
            CONNECT_OFFSET_STORAGE_TOPIC: _connect-offsets
            CONNECT_STATUS_STORAGE_TOPIC: _connect-status
            CONNECT_KEY_CONVERTER: org.apache.kafka.connect.storage.StringConverter
            CONNECT_VALUE_CONVERTER: io.confluent.connect.avro.AvroConverter
            CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: 'http://schema-registry:8081'
            CONNECT_REST_ADVERTISED_HOST_NAME: "kafka-connect"
            CONNECT_LOG4J_APPENDER_STDOUT_LAYOUT_CONVERSIONPATTERN: "[%d] %p %X{connector.context}%m (%c:%L)%n"
            CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: "1"
            CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: "1"
            CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: "1"
        #  ---------------
            CONNECT_PLUGIN_PATH: /usr/share/java,/usr/share/confluent-hub-components,/data/connect-jars
        # If you want to use the Confluent Hub installer to d/l component, but make them available
        # when running this offline, spin up the stack once and then run : 
        #   docker cp kafka-connect:/usr/share/confluent-hub-components ./data/connect-jars
        volumes:
            - $PWD/data:/data
        # In the command section, $ are replaced with $$ to avoid the error 'Invalid interpolation format for "command" option'
        command:
            - bash
            - -c
            - |
                echo "Installing Connector"
                confluent-hub install --no-prompt confluentinc/kafka-connect-jdbc:10.2.0
                confluent-hub install --no-prompt confluentinc/kafka-connect-elasticsearch:11.0.4
                #
                echo "Launching Kafka Connect worker"
                /etc/confluent/docker/run &
                #
                sleep infinity

    ksqldb-server:
        # *-----------------------------*
        # To connect to ksqlDB CLI
        #   docker exec --interactive --tty ksqldb ksql http://localhost:8088
        # *-----------------------------*
        image: confluentinc/cp-ksqldb-server:latest
        hostname: ksqldb
        container_name: ksqldb
        depends_on:
            - kafka
            - schema-registry
        ports:
            - 8088:8088
        environment:
            KSQL_CONFIG_DIR: "/etc/ksql"
            KSQL_LISTENERS: http://0.0.0.0:8088
            KSQL_BOOTSTRAP_SERVERS: kafka:29092
            KSQL_KSQL_LOGGING_PROCESSING_STREAM_AUTO_CREATE: "true"
            KSQL_KSQL_LOGGING_PROCESSING_TOPIC_AUTO_CREATE: "true"
            KSQL_KSQL_SCHEMA_REGISTRY_URL: http://schema-registry:8081
            KSQL_STREAMS_PRODUCER_MAX_BLOCK_MS: 9223372036854775807
            KSQL_KSQL_CONNECT_URL: http://kafka-connect:8083
            KSQL_KSQL_SERVICE_ID: confluent_rmoff_01
            KSQL_KSQL_HIDDEN_TOPICS: '^_.*'

    ksqldb-cli:
        image: confluentinc/cp-ksqldb-cli:latest
        container_name: ksqldb-cli
        depends_on:
            - kafka
            - kafka-connect
            - ksqldb-server
        entrypoint: /bin/sh
        tty: true

volumes:
    data01:
        driver: local